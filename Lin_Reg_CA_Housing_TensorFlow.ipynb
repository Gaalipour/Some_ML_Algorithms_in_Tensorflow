{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with Tensorflow\n",
    "### Fiting to linear function to our data:\n",
    "$$ y = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\cdots + \\theta_n x_n$$\n",
    "\n",
    "### Objective: \n",
    "* Finding the best values of parameters $\\theta_0, \\theta_1, \\ldots, \\theta_n$ minimizing error MSE. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression (Image from Wikipedia):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEJCAYAAAC61nFHAAAABGdBTUEAALGPC/xhBQAAACBjSFJN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\nRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='Linear_regression.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods for Linear Regression:\n",
    "\n",
    "#### 1. Normal Equation\n",
    "We explicitly determine the value of the parameter vector $\\theta = (\\theta_0, \\theta_1, \\ldots, \\theta_n)$ through the following equation:\n",
    "+ Let **$X$** be our input data\n",
    "+ Let $y$ be target variable\n",
    "\n",
    "Then $\\theta = (X^tX)^{-1}X^ty$. \n",
    "\n",
    "\n",
    "#### 2. (Batch) Gradianet Decent Algorithm:\n",
    "* Find the gradianet of MSE\n",
    "* Update the vector parameter $\\theta = (\\theta_0, \\theta_1, \\ldots, \\theta_n)$ by $\\theta := \\theta - \\lambda\\nabla(MSE)$, where $\\lambda$ is our learning rate. \n",
    "* Do it until you arrive in a predifnined iteration or you arrive in your desired error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Normal Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.datasets.base.Bunch"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "type(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California housing dataset.\n",
      "\n",
      "The original database is available from StatLib\n",
      "\n",
      "    http://lib.stat.cmu.edu/\n",
      "\n",
      "The data contains 20,640 observations on 9 variables.\n",
      "\n",
      "This dataset contains the average house value as target variable\n",
      "and the following input variables (features): average income,\n",
      "housing average age, average rooms, average bedrooms, population,\n",
      "average occupation, latitude, and longitude in that order.\n",
      "\n",
      "References\n",
      "----------\n",
      "\n",
      "Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "Statistics and Probability Letters, 33 (1997) 291-297.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(housing.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0368</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.761658</td>\n",
       "      <td>1.103627</td>\n",
       "      <td>413.0</td>\n",
       "      <td>2.139896</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.6591</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.931907</td>\n",
       "      <td>0.951362</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>2.128405</td>\n",
       "      <td>37.84</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.1200</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.797527</td>\n",
       "      <td>1.061824</td>\n",
       "      <td>1157.0</td>\n",
       "      <td>1.788253</td>\n",
       "      <td>37.84</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0804</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.294118</td>\n",
       "      <td>1.117647</td>\n",
       "      <td>1206.0</td>\n",
       "      <td>2.026891</td>\n",
       "      <td>37.84</td>\n",
       "      <td>-122.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.6912</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.970588</td>\n",
       "      <td>0.990196</td>\n",
       "      <td>1551.0</td>\n",
       "      <td>2.172269</td>\n",
       "      <td>37.84</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "5  4.0368      52.0  4.761658   1.103627       413.0  2.139896     37.85   \n",
       "6  3.6591      52.0  4.931907   0.951362      1094.0  2.128405     37.84   \n",
       "7  3.1200      52.0  4.797527   1.061824      1157.0  1.788253     37.84   \n",
       "8  2.0804      42.0  4.294118   1.117647      1206.0  2.026891     37.84   \n",
       "9  3.6912      52.0  4.970588   0.990196      1551.0  2.172269     37.84   \n",
       "\n",
       "   Longitude  \n",
       "0    -122.23  \n",
       "1    -122.22  \n",
       "2    -122.24  \n",
       "3    -122.25  \n",
       "4    -122.25  \n",
       "5    -122.25  \n",
       "6    -122.25  \n",
       "7    -122.25  \n",
       "8    -122.26  \n",
       "9    -122.25  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heads = housing.feature_names\n",
    "\n",
    "hdata = pd.DataFrame(housing.data, columns = heads)\n",
    "hdata.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, n = hdata.shape ## Dimension of data\n",
    "m,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.526],\n",
       "       [ 3.585],\n",
       "       [ 3.521],\n",
       "       ..., \n",
       "       [ 0.923],\n",
       "       [ 0.847],\n",
       "       [ 0.894]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We get traget variable by housing.target and then make it into a long column\n",
    "\n",
    "housing.target.reshape(-1,1) ### the same as housing.target.reshape(m,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding bias (all-one) as a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Biased_Term</th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Biased_Term  MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  \\\n",
       "0          1.0  8.3252      41.0  6.984127   1.023810       322.0  2.555556   \n",
       "1          1.0  8.3014      21.0  6.238137   0.971880      2401.0  2.109842   \n",
       "2          1.0  7.2574      52.0  8.288136   1.073446       496.0  2.802260   \n",
       "3          1.0  5.6431      52.0  5.817352   1.073059       558.0  2.547945   \n",
       "4          1.0  3.8462      52.0  6.281853   1.081081       565.0  2.181467   \n",
       "\n",
       "   Latitude  Longitude  \n",
       "0     37.88    -122.23  \n",
       "1     37.86    -122.22  \n",
       "2     37.85    -122.24  \n",
       "3     37.85    -122.25  \n",
       "4     37.85    -122.25  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data] ## Adding bias (all-one) as a new column\n",
    "biased_data = pd.DataFrame(housing_data_plus_bias, columns = [\"Biased_Term\"] +heads)\n",
    "biased_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.74651413e+01],\n",
       "       [  4.35734153e-01],\n",
       "       [  9.33829229e-03],\n",
       "       [ -1.06622010e-01],\n",
       "       [  6.44106984e-01],\n",
       "       [ -4.25131839e-06],\n",
       "       [ -3.77322501e-03],\n",
       "       [ -4.26648885e-01],\n",
       "       [ -4.40514028e-01]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "    \n",
    "theta_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Will get the same by pure NumPy or Scikit-learn?\n",
    "\n",
    "### We first compute $\\theta$ by pure numpy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.69419202e+01],\n",
       "       [  4.36693293e-01],\n",
       "       [  9.43577803e-03],\n",
       "       [ -1.07322041e-01],\n",
       "       [  6.45065694e-01],\n",
       "       [ -3.97638942e-06],\n",
       "       [ -3.78654265e-03],\n",
       "       [ -4.21314378e-01],\n",
       "       [ -4.34513755e-01]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = housing_data_plus_bias\n",
    "y = housing.target.reshape(-1, 1)\n",
    "theta_numpy = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "theta_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\theta$ by Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.69419202e+01],\n",
       "       [  4.36693293e-01],\n",
       "       [  9.43577803e-03],\n",
       "       [ -1.07322041e-01],\n",
       "       [  6.45065694e-01],\n",
       "       [ -3.97638942e-06],\n",
       "       [ -3.78654265e-03],\n",
       "       [ -4.21314378e-01],\n",
       "       [ -4.34513755e-01]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing.data, housing.target.reshape(-1, 1))\n",
    "\n",
    "scikitlrn_theta = (np.r_[lin_reg.intercept_.reshape(-1, 1), lin_reg.coef_.T])\n",
    "scikitlrn_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually Computing Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 9.16154\n",
      "Epoch 100 MSE = 0.714501\n",
      "Epoch 200 MSE = 0.566705\n",
      "Epoch 300 MSE = 0.555572\n",
      "Epoch 400 MSE = 0.548812\n",
      "Epoch 500 MSE = 0.543636\n",
      "Epoch 600 MSE = 0.539629\n",
      "Epoch 700 MSE = 0.536509\n",
      "Epoch 800 MSE = 0.534068\n",
      "Epoch 900 MSE = 0.532147\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\") # Random inotialization of weights\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\") ## Mean of square errors\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients) # Assigns a new value to theta\n",
    "\n",
    "init = tf.global_variables_initializer() ## Initialize all variables\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval()) \n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.06855249],\n",
       "       [ 0.88740271],\n",
       "       [ 0.14401658],\n",
       "       [-0.34770882],\n",
       "       [ 0.36178368],\n",
       "       [ 0.00393812],\n",
       "       [-0.04269557],\n",
       "       [-0.66145277],\n",
       "       [-0.63752776]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using autodiff\n",
    "Same as above except for the __gradients = ... line__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gradients = tf.gradients(mse, [theta])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 9.16154\n",
      "Epoch 100 MSE = 0.714501\n",
      "Epoch 200 MSE = 0.566705\n",
      "Epoch 300 MSE = 0.555572\n",
      "Epoch 400 MSE = 0.548812\n",
      "Epoch 500 MSE = 0.543636\n",
      "Epoch 600 MSE = 0.539629\n",
      "Epoch 700 MSE = 0.536509\n",
      "Epoch 800 MSE = 0.534068\n",
      "Epoch 900 MSE = 0.532147\n",
      "Best theta:\n",
      "[[ 2.06855249]\n",
      " [ 0.88740271]\n",
      " [ 0.14401658]\n",
      " [-0.34770882]\n",
      " [ 0.36178368]\n",
      " [ 0.00393811]\n",
      " [-0.04269556]\n",
      " [-0.66145277]\n",
      " [-0.6375277 ]]\n"
     ]
    }
   ],
   "source": [
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a GradientDescentOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 9.16154\n",
      "Epoch 100 MSE = 0.714501\n",
      "Epoch 200 MSE = 0.566705\n",
      "Epoch 300 MSE = 0.555572\n",
      "Epoch 400 MSE = 0.548812\n",
      "Epoch 500 MSE = 0.543636\n",
      "Epoch 600 MSE = 0.539629\n",
      "Epoch 700 MSE = 0.536509\n",
      "Epoch 800 MSE = 0.534068\n",
      "Epoch 900 MSE = 0.532147\n",
      "Best theta:\n",
      "[[ 2.06855249]\n",
      " [ 0.88740271]\n",
      " [ 0.14401658]\n",
      " [-0.34770882]\n",
      " [ 0.36178368]\n",
      " [ 0.00393811]\n",
      " [-0.04269556]\n",
      " [-0.66145277]\n",
      " [-0.6375277 ]]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a momentum optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best theta:\n",
      "[[ 2.06855798]\n",
      " [ 0.82962859]\n",
      " [ 0.11875337]\n",
      " [-0.26554456]\n",
      " [ 0.30571091]\n",
      " [-0.00450251]\n",
      " [-0.03932662]\n",
      " [-0.89986444]\n",
      " [-0.87052065]]\n"
     ]
    }
   ],
   "source": [
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "\"\"\"\n",
    "Based on the given index, returns the corersponding batch of data\n",
    "\"\"\"\n",
    "def fetch_batch(epoch, batch_index, batch_size): \n",
    "    np.random.seed(epoch * n_batches + batch_index)  \n",
    "    indices = np.random.randint(m, size=batch_size)  \n",
    "    X_batch = scaled_housing_data_plus_bias[indices] \n",
    "    y_batch = housing.target.reshape(-1, 1)[indices] \n",
    "    return X_batch, y_batch\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.07033372],\n",
       "       [ 0.86371452],\n",
       "       [ 0.12255151],\n",
       "       [-0.31211874],\n",
       "       [ 0.38510373],\n",
       "       [ 0.00434168],\n",
       "       [-0.01232954],\n",
       "       [-0.83376896],\n",
       "       [-0.80304712]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing Graphs Using TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:                                                        # not shown in the book\n",
    "    sess.run(init)                                                                # not shown\n",
    "\n",
    "    for epoch in range(n_epochs):                                                 # not shown\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
